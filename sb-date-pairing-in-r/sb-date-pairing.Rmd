---
title: "Date Pairing in R"
output: 
 learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(data.table)
library(dplyr)
library(pwr)
library(tidyr)
library(stats)
library(ggplot2)
library(sortable)
shhh <- suppressPackageStartupMessages
shh <- suppressWarnings
sh <- suppressMessages
knitr::opts_chunk$set(echo = FALSE)
options(digits = 3, scipen = 9999)
tutorial_options(exercise.completion = FALSE,
                 exercise.eval = TRUE,
                 exercise.lines = 8,
                 exercise.diagnostics = TRUE)

math <- read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeMath.csv")
lang <- read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeLang.csv")

mathr <- rename(.data = math, id = subjectID, date = testDate, score = mathScore)
langr <- rename(.data = lang, id = subjectID, date = testDate, score = languageScore)


```

## The Problem

Let’s say **you want to look at two measurements** for a patient or a research participant to find some relationship between them (like a score on an anxiety measure for one variable and triglyceride levels for a few others); but some patients have **multiple records for one or both instruments or measures**. 

**How can you find the right records to use in your research?** If you don’t limit which repeated measures you use, you’ll end up with more than one row per patient, which you don’t want.

Maybe you want the two measurements to be as close as possible in time. Or maybe you want the earliest anxiety measure and whatever triglyceride is nearest it (say, 40 days earlier), even if that *interval* isn’t the smallest (say the patient later had an anxiety workup and lipids lab on the same day). There are lots of possibilities here, and they all depend on your research purpose.

```{r what-problems-to-solve, echo=FALSE}
question("What problem do we want to solve by pairing dates?",
         answer("We want to compare two variables but we have multiple records for some patients, either in the responses to one instrument or in two or more instruments", correct = TRUE),
         answer("There is no research question", message = "We may not have a research question, but more study and thought rather than pairing dates will help us solve that problem."),
         answer("2008/1.33", message = "That's a math problem. Date pairing will not help you. Try typing it into the console if you really want to solve it."),
         answer("We want to identify unique cases and keep only those", message = "You can solve this by widening both data sets, binding their rows, and passing the new data set name to `unique`. Date pairing will not help you."),
         correct = "You are amazing!",
         incorrect = "Incorrect.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

## Example Data

Let’s consider some fake data [Joy Payton](education.arcus.chop.edu) created for illustration purposes: 500 records of fake math scores and fake language scores. Joy stored them on her github repo. 

Uncomment the lines in the code box below. 

[HINT: In RStudio, you can select all the lines you want to uncomment or comment, then press `cmd` (if you have a Mac) or `ctrl` (if you have a PC) along with `shift-c`. This key combination is a toggle: a great way to uncomment or comment large blocks of code. You can't do that here, though. Here, delete the `#` and any accompanying spaces at the beginning of each line to uncomment code.]

[ANOTHER HINT: Press `option` (Mac) or `alt` (PC) and select the first 2 _columns_ of the three lines of code. The cursor should grow or multiply in the direction you move it as long as you hold down the `option/alt` key while selecting. This really cool feature from the RStudio team allows you to select items in sequence---while _not_ holding down the `option/alt` key while you select---_or_ in rectangles---while holding down the `option/alt` key while you select.]

After uncommenting the lines, run the code: Press `cmd` or `ctrl` and `Enter` at the same time or click on the "Run Code" button. These commands download the two data files and stores them in the two tibbles named `math` and `lang`.

```{r load-data, exercise = TRUE, exercise.lines = 5}
# library(tidyverse)
# math <- as_tibble(read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeMath.csv"))
# lang <- as_tibble(read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeLang.csv"))
```
```{r load-data-solution}
library(tidyverse)
math <- as_tibble(read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeMath.csv"))
lang <- as_tibble(read.csv("https://raw.githubusercontent.com/pm0kjp/datastore/master/fakeLang.csv"))
```

We store the data in two tibbles, which are data frames that are nicely formatted. Have a look at them by typing their names, one per line, and executing the code. 

```{r seemath-lang, exercise = TRUE, exercise.lines = 5}

```
```{r seemath-lang-hint}
math
...
```
```{r seemath-lang-solution}
math
lang
```

If you have worked with non-tibble data frames before, you might prefer tibble output. I do. I try to put all my data frames in tibble format except when I come across the odd function that prefers to be passed the traditional data frame format. If that happens, I wrap the tibble in `as.data.frame` before passing it to the fussy function.

>The tidyverse prefers tibbles.

You've already put [the `tidyverse` packages](https://tidyverse.tidyverse.org) in the library, so you don't have to do that again. Note that `tidyverse` is not a single package but is, as is stated on its website,

>a group of packages that work in harmony because they share common representations and [API design](https://mattgemmell.com/api-design/).


(You can [learn more about APIs](https://mattgemmell.com/api-design/) or simply replace the word "API" in your head with "user interface for developers" when you come it.)

### Simplify Variable Names

We're lazy programmers, so let's simplify our variable names and make sure they are all in lowercase letters. This is good coding practice because, if you lowercase everything, although you will find yourself checking the spelling of variables, you will never find yourself checking to see which letters are upper- and which are lowercase. 

We'll use the `tidyverse`'s `rename` function. 

The format for using `rename` is to type the function name, then pass it the arguments `data = math` or `lang` and `id = subjectID`. The correct syntax involves putting the "to" variable name first, then setting it equal to the "from" variable.

Do this for both tibbles, renaming `subjectID` to `id`, `testDate` to `date`, and the score variables to `score`. Make sure you store the results in modified tibble names, the same names as before with an "r" on the end. 

```{r rename-vars, exercise = TRUE, exercise.lines = 5}

```
```{r rename-vars-hint-1}
mathr <- rename(...)
```
```{r rename-vars-hint-2}
mathr <- rename(.data = math, ...)
rename(.data = lang, ...)
```
```{r rename-vars-hint-3}
mathr <- rename(.data = math, id = subjectID, ...)
langr <- rename(.data = lang, ...)
```
```{r rename-vars-solution}
mathr <- rename(.data = math, id = subjectID, date = testDate, score = mathScore)
langr <- rename(.data = lang, id = subjectID, date = testDate, score = languageScore)
```

You won't see anything happen because the output is going to the new tibble names, `math` and `lang`.

### The Data

The data has the following qualities:

* Each of the two data sets `math` and `lang` has 500 samples and 3 variables    
* IDs are integers between 1 and 1000    
* Dates are randomly and uniformly distributed between January 1, 2005 and January 1, 2016    
* Each `id` may have one or more `date`s associated with it because people can take the tests repeatedly
* Scores follow a triangular distribution with     
  - a minimum of 25 (indicates full guessing)    
  - a maximum of 100    
  - a mode of 80
* scores are rounded

## Look at the Data

You can learn more about looking at data by going through our [Looking at Data lesson](http://a-mess.org/swirl-looking-at-data/). We'll be using some of the methods from that lesson here.

Let's use a variety of functions to confirm what we told you about the data. 

### 1. Prepare: Get the `names` to Pass to Other Functions

Find the variable names in `mathr` and `langr` by passing each one to the `names` function. Separate the two calls to `names` using a `;`. That's how you put two R commands on a single line. I don't do it often, but ocassionally, as here, it's more readable to put simple, repetitive statements together on the same line.

You should see three names for each data set as a result. Each data set has the _same_ set of three names. 

```{r names, exercise = TRUE, exercise.lines = 5}

```
```{r names-hint-1}
names(...)
```
```{r names-hint-2}
names(...); names(...)
```
```{r names-hint-3}
names(mathr); names(...)
```
```{r names-solution}
names(mathr); names(langr)
```

### 2. Confirm the Number of Samples with `dim`

Do something similar to what you did with `names`, but this time, replace the calls to `names` with calls to `dim`. 

You can copy your code from the previous code chunk and replace just two words.


```{r dims, exercise = TRUE, exercise.lines = 5}

```
```{r dims-hint-1}
dim(...)
```
```{r dims-hint-2}
dim(...); dim(...)
```
```{r dims-hint-3}
dim(mathr); dim(...)
```
```{r dims-solution}
dim(mathr); dim(langr)
```

### 3. Confirm the Range of `id` and `score` with `range`

Use the function `range`, passing it `mathr$id`, then `langr$id`. Repeat that line with `mathr$score` and `langr$score`.

```{r range, exercise = TRUE, exercise.lines = 5}

```
```{r range-hint-1}
range(...)
range(...)
```
```{r range-hint-2}
range(...); range(...)
range(...); range(...)
```
```{r range-hint-3}
range(mathr$id); range(langr$id)
range(...)
```
```{r range-solution}
range(mathr$id); range(langr$id)
range(mathr$score); range(langr$score)
```

```{r range_id, echo=FALSE}
question("Do all the values in `id` fall within the expected range for both data sets?",
         answer("Yes", correct = TRUE),
         answer("No", message = "Check the hints in the code block to see where you may have gone wrong."),
         correct = "Well done.",
         incorrect = "They do.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

```{r what-next-if-out-of-range, echo=FALSE}
question("What would you have done if the range of `id`s had been outside of 1 through 1000?",
         answer("Look more closely at the data to figure out why.", correct = TRUE),
         answer("Assume that both variables are not as we thought", message = "Any time you hear or think 'assume' anything, don't stop there. Ask yourself how you can ascertain the truth of the assumption."),
         answer("Move along because `id` is not an important variable", message = "Have you any reason to believe that this is an unimportant variable besides the fact that it is called `id`?"),
         answer("Reset all the `id`s in both data sets so they fall within the expected range", message = "Have you ascertained that each `id` is used only once? Until you know more, you should leave their values alone."),
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```


### Is `date` a Date?

Find out what class the `date` variable is for each data set using the `class` function. You can separate the two calls (one each for `mathr` and `langr`) by a semicolon as you did with `dim` and `names` above. 

```{r check-date-class, exercise = TRUE, exercise.lines = 5}

```
```{r check-date-class-hint-1}
class(...)
```
```{r check-date-class-hint-2}
class(mathr$date); class(...)
```
```{r check-date-class-solution}
class(mathr$date); class(langr$date)
```

```{r is-date-date, echo=FALSE}
question("Is the variable `date` a date class in either data set?",
         answer("No", correct = TRUE),
         answer("Yes", message = "Type `class(mathr$date); class(langr$date)`"),
         correct = "That's absolutely right.",
         incorrect = "No.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```


### 5. See the `head` of the `date`s

Look at the top of the `date` variables by passing them to `head`.

```{r head-date, exercise = TRUE, exercise.lines = 5}

```
```{r head-date-hint-1}
head(...)
```
```{r head-date-hint-2}
head(mathr$date); head(...)
```
```{r head-date-solution}
head(mathr$date); head(langr$date)
```

### 6. Check `score` Distributions (and Find the Modes)

```{r check-score-distros, exercise = TRUE, exercise.lines = 5}

```
```{r check-score-distros-hint-1}
hist(...)
```
```{r check-score-distros-hint-2}
hist(...); hist(...)
```
```{r check-score-distros-hint-3}
hist(mathr$score); hist(...)
```
```{r check-score-distros-solution}
hist(mathr$score); hist(langr$score)
```

```{r triangular-yn, echo=FALSE}
question("Do the `score` distributions look triangular?",
         answer("Yes", correct = TRUE),
         answer("No", message = "Type `hist(mathr$score); hist(langr$score)` and look carefully."),
         correct = "That's right!",
         incorrect = "Incorrect.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```
```{r wheremode, echo=FALSE}
question("Where are the `score` modes (as shown by the histograms)?",
         answer("Around 80", correct = TRUE),
         answer("Around 60"),
         answer("Around 0"),
         correct = "You are doing so well!",
         incorrect = "Actually no. Look for the tallest bars in each of the histograms",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

### Fix One Thing

```{r fix-one-thing, echo=FALSE}
question("If you could fix one thing about the data set, what would it be?",
         answer("Change the date from a factor to a date object", correct = TRUE),
         answer("Eliminate all duplicate `id`s", message = "Duplicate `id`s exist because each person may have taken the test more than once."),
         answer("Make `mathr` wider", message = "`mathr` doesn't contain any implicit variables."),
         answer("Make `langr` wider", message = "`langr` doesn't contain any implicit variables."),
         correct = "You got it!",
         incorrect = "That's not the answer I was looking for.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

## Identify Duplicates using `dplyr`

First, let's find out if you need to review `dplyr`.

```{r select-verbs, echo=FALSE}
question("Which of these are `dplyr` verbs? Select six.",
         answer("`select`", correct = TRUE),
         answer("`unselect`"),
         answer("`disregard`"),
         answer("`rename`", correct = TRUE),
         answer("`mutate`", correct = TRUE),
         answer("`filter`", correct = TRUE),
         answer("`summarise`", correct = TRUE),
         answer("`arrange`", correct = TRUE),
         correct = "You are amazing!",
         incorrect = "Check out `dplyr.tidyverse.org` for the answer.",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```
```{r whatsapipe, echo=FALSE}
question("What does a `dplyr` pipe look like?",
         answer("%>%", correct = TRUE),
         answer("%->%", message = "message_wrong_1"),
         answer("%=%", message = "message_wrong_2"),
         answer("%<%", message = "message_wrong_3"),
         correct = "Yes!",
         incorrect = "No, that's not a pipe in `dplyr` terms. Check out `dplyr.tidyverse.org` to find out more",
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

If you struggled to figure out the answers to these questions, please see [our `dplyr`](../sb-dplyr/) and [Piping and Summarizing](../sb-piping-and-summarizing/) lessons before continuing. The rest of this lesson assumes you have an understanding of those concepts.

Our two data sets are tables (matrices). How many duplicates have we in each table? We can use `dplyr` to group by subject `id`, find the how big each group is, and display results in a table, ordered by group size. Follow these steps:

1. Make sure `dplyr` is in the library by typing `library(dplyr)`.     
2. Start with `mathr` and pipe it to `group_by`.    
3. Pass `id` to `group_by`, then add another pipe.    
4. Call the function `group_size`, then add another pipe.    
5. Call the function `table`.

```{r first-piping, exercise = TRUE, exercise.lines = 7}

```
```{r first-piping-hint-1}
library(...)
```
```{r first-piping-hint-2}
library(dplyr)
mathr %>% 
  ...
```
```{r first-piping-hint-3}
library(dplyr)
mathr %>% 
  group_by(...) %>%
  ...
```
```{r first-piping-hint-4}
library(dplyr)
mathr %>% 
  group_by(id) %>%
  group_size %>%
  ...
```
```{r first-piping-solution}
library(dplyr)
mathr %>% 
  group_by(id) %>%
  group_size %>%
  table
```

Lots of duplication here. One participant took the math test four times! Still, most (329) made only one attempt.

Go ahead and use this code chunk to run the same series of steps with `langr` as input data.

```{r langr-piping, exercise = TRUE, exercise.lines = 5}

```
```{r langr-piping-hint-1}
langr %>%
  ...
```
```{r langr-piping-hint-2}
langr %>%
  group_by(...) %>%
```
```{r langr-piping-hint-3}
langr %>%
  group_by(id) %>%
  group_size %>%
  ...
```
```{r langr-piping-solution}
langr %>%
  group_by(id) %>%
  group_size %>%
  table
```

Similar here – lots of people took the tests more than once. 

```{r howmanythisthat, echo=FALSE}
question("How many people took the language test twice?",
         answer("86", correct = TRUE),
         answer("295", message = "That's how many took it once."),
         answer("11", message = "That's how many took it 3 times."),
         answer("0", message = "I'm afraid something went seriously wrong with your code if you have a 0 somewhere."),
     correct = "That's right!",
     incorrect = "No.",
     random_answer_order = TRUE,
     allow_retry = TRUE
)
```
```{r howmanymath, echo=FALSE}
question("How many people took the math test at least twice?",
         answer("82", correct = TRUE),
         answer("76", message = "That's how many people took it twice. I asked how many people too the test _at least_ twice."),
         answer("5", message = "That's how many people took the test 3 times. Add a few more to the total and you'll get the right answer."),
         answer("1", message = "Four times is _at least_ twice, but you should add in those who took it twice and three times as well."),
     correct = "You got it!",
     incorrect = "No.",
     random_answer_order = TRUE,
     allow_retry = TRUE
)
```

If we were to merge these data frames by `id` without limiting by dates, we would have geometric growth. For example, consider subject 697. This subject has 3 took both the math and the language tests three times. A traditional `merge` function will match each _possible_ combination, for 3 X 3 or 9 rows in the resulting data set. Let's try that. 

```{r merge3x3, exercise = TRUE, exercise.lines = 5}

```
```{r merge3x3-hint-1}
code
```
```{r merge3x3-hint-2}
code
```
```{r merge3x3-hint-3}
code
```
```{r merge3x3-hint-4}
code
```
```{r merge3x3-solution}
code
```


Having so much repetition can causes problems with analyses that assume one observation or one combination of observations per subject. So, how can we limit the number of rows returned when we combine the math and language scores to just one row per subject?

We can imagine several ways to accomplish this:

“Give me the earliest language score, if any, and the math score closest in time to that language score. If no language score, omit.”

“I don’t care if it’s a first test or a subsequent readministration, just give me the smallest time interval between a language and a math for each subject that has both.”

“Give me the closest math score and the closest language score to this subject’s MRI date, which I’ll give you.”

“Give me the closest math date after language – if math precedes language, I don’t want to see it.”

We have to keep a few things in mind: some instruments (like some psychometric instruments) should only really be administered once, so we will probably want to disregard administrations 2-n, no matter when they occurred. Some instruments, like lab results, have roughly defined “expiration dates” – they reflect a moment in time, and must be selected carefully to make sure you’re measuring what you want, when you want. An expired measurement may be worse than no data at all in this case. Some instruments might need to be administered in order – for example, we might want an instrument that requires deception to be administered before other measures that tend to tip participants off to the purpose of the deceptive instrument. It is very important to understand our precise research goals as well as the specifications of the measurement when working with data that needs to have multiple administrations resolved.

Let’s take a look at some common tactics with date-based resolution!

We begin by making sure that dates are dates:

math$testDate <- as.Date(math$testDate)
lang$testDate <- as.Date(lang$testDate)
OPTION 1: Closest pairs

Let’s consider what we would do if we just wanted to get the closest date-matched set of math and language scores – maybe we are doing research into the correlation of scores between the two tests. If subjects have only one of the two, leave them out of the set.

First we merge. R’s merge command by default only takes the intersection (the overlap in the Venn diagram) of two datasets, as defined by their “by” field. Since our two data frames have the same column name for the date of administration, we’ll want to add suffixes to clarify which is which.

pairs <- merge(math, lang, by="subjectID", suffixes=c(".math", ".lang"))
Check out the data frame:

head(pairs)
	  subjectID testDate.math mathScore testDate.lang languageScore
	1        12    2006-06-24        64    2009-10-30            86
	2        20    2008-08-23        72    2015-12-17            62
	3        20    2008-08-23        72    2008-10-14            56
	4        35    2015-11-25        76    2005-04-04            82
	5        45    2005-05-03        71    2010-08-06            53
	6        48    2007-03-24        83    2007-01-02            63
The pairs data frame consists of rows that each have a math and a lang score, but some subjects have multiple rows. Confirm this by asking dplyr to group, count, and then display in descending order the number of rows for each subject.

pairs %>% 
  group_by(subjectID) %>% 
  summarise(size = n()) %>% 
  arrange(desc(size)) %>%
  ungroup()
	# A tibble: 161 x 2
	   subjectID  size
	       <int> <int>
	 1       697     9
	 2       119     4
	 3       216     4
	 4       329     4
	 5       726     4
	 6       878     4
	 7       985     4
	 8       262     3
	 9       485     3
	10       623     3
	# ... with 151 more rows
Yep, the dratted 697 is there. How will we select the closest pair for each subject?

One easy way is to use dplyr. We’ve already merged all the options, so now we just want to filter pairs such that within each ID, the only row we keep is the one with the smallest time interval. That’s fairly simple. We don’t care about order, so we just look for the smallest absolute value in date difference, or, to say it another way, the difference that is the same as the minimum difference for this ID.

Note that we have to think about ties – say, there’s a math test 200 days prior to and one 200 days after the language test. In our case, it doesn’t matter which one we pick, so we just take the first one, using dplyr’s slice(). Finally, we’ll ungroup the resultant data frame.

closestPairs <- pairs %>% 
  group_by(subjectID) %>%
  filter(abs(testDate.lang - testDate.math) == min(abs(testDate.lang - testDate.math))) %>%
  slice(1) %>% 
  ungroup()
How big is this data?

dim(closestPairs)
	[1] 161   5
closestPairs only has 161 rows, as compared to 250 for pairs. Let’s confirm that there are no duplications:

table(duplicated(closestPairs$subjectID))
	FALSE 
	  161
All false. We have a data frame that consists of only the subjects that have both tests, and from those administrations, only the pair that has the smallest interval of time.

OPTION 2: Earliest math and nearest language (if any)

Here we want all subjects that have a math score. We’ll take their first one, then find the nearest language score (if there is one) to that.

Here, we’ll merge more than just the intersection – we’ll also include cases in which math is present but language is absent. In other words, we want ALL the math rows, regardless of whether there’s a corresponding language row. We can’t say the same about language.

earliestMath <- merge(x=math, y=lang, by="subjectID", 
                      all.x = TRUE, suffixes = c(".math", ".lang"))
Now we’ll do something similar to option 1 above, as far as selecting the smallest absolute value, but we’ll have to include cases where there is no date distance (it’s na), because there isn’t a language date to use to calculate from. We use the vertical pipe (|) to symbolize OR: is.na(testDate.lang - testDate.math)`.

firstMathMaybeLanguage <- earliestMath %>% 
  group_by(subjectID) %>%
  filter(abs(testDate.lang - testDate.math) == min(abs(testDate.lang - testDate.math)) | is.na(testDate.lang - testDate.math)) %>%
  slice(1) %>% 
  ungroup()
Again, let’s look at how large our data is.

dim(firstMathMaybeLanguage)
	[1] 411   5
firstMathMaybeLanguage has 411 rows. Let’s confirm that there are no duplicates:

table(duplicated(firstMathMaybeLanguage$subjectID))
	FALSE 
	  411
Great, we have data with no duplicated subjects.

## References 

The originator of this lesson as well as the author of the data is Joy Payton. You can find [Joy's original lesson here](https://education.arcus.chop.edu/date-pairing-in-r/).
