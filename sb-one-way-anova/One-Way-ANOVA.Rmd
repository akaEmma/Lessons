---
title: "One Way ANOVA"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(data.table)
library(dplyr)
library(pwr)
library(tidyr)
library(stats)
library(ggplot2)
shhh <- suppressPackageStartupMessages
shh <- suppressWarnings
sh <- suppressMessages
knitr::opts_chunk$set(echo = FALSE)
options(digits = 3, scipen = 9999)
tutorial_options(exercise.completion = FALSE,
                 exercise.eval = TRUE,
                 exercise.lines = 8,
                 exercise.diagnostics = TRUE)

Input = ("
Tillamook Newport Petersburg  Magadan Tvarminne
0.0571	0.0873	0.0974	0.1033	0.0703
0.0813	0.0662	0.1352	0.0915	0.1026
0.0831	0.0672	0.0817	0.0781	0.0956
0.0976	0.0819	0.1016	0.0685	0.0973
0.0817	0.0749	0.0968	0.0677	0.1039
0.0859	0.0649	0.1064	0.0697	0.1045
0.0735	0.0835	0.105	  0.0764	NA
0.0659	0.0725	0.0689  NA  NA
0.0923  NA  NA  NA  NA
0.0836  NA  NA  NA  NA
")
mussels <- read.table(textConnection(Input), header = TRUE)
rm(Input)
long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam")
long_mussels$location <- as.factor(long_mussels$location)
```

## Background

This lesson is both a reference and a tutorial. It contains all the code samples you need to perform a one-way ANOVA on your own data as well as background information such as how to interpret output and which graphs you might want to use to demonstrate results (and in some cases which graphs _not_ to use). 

## What kinds of Variables work with One-Way ANOVA

>One [scalar (a.k.a. "measurement") variable](http://www.biostathandbook.com/variabletypes.html#measurement).     
One [nominal (a.k.a. "categorical") variable](http://www.biostathandbook.com/variabletypes.html#nominal)   

The nominal variable divides the measurements into two or more groups. The one-way ANOVA tests whether the means of the measurement variable are the same for the different groups.

## Null and Alternative Hypotheses

>* **H<sub>0</sub>**: The means of the measurement variable are the
same for the different categories in the nominal (a.k.a. "categorical") variable.     
* **H<sub>A</sub>**: The means are not all the same for the different categories in the categorical variable.   

```{r bb, echo=FALSE}
question("Which are examples of a one-way ANOVA null hypotheses?",
         answer("Mean tibia length is the same for each age group of children", correct = TRUE),
         answer("The average monthly electric bill is the same in major cities within the United States", correct = TRUE),
         answer("The average monthly electric bill in Philadelphia, PA is less than what it is in Burlington, VT"),
         answer("The average monthly electric bill in Philadelphia, PA is more than what it is in Burlington, VT"),
         allow_retry = TRUE,
         random_answer_order = TRUE,
         incorrect = "Remember that the one-way ANOVA tests whether the means of the measurement variable are teh same for different groups.",
         correct = "Yes!"
)
```

## When to use an ANOVA

Analysis of variance (ANOVA) is the most commonly used technique for __comparing the means of groups__ of measurement data. You can analyze lots of different experimental designs with different kinds of ANOVA. Here we will discuss only the simplest ANOVA.

```{r whentouseANOVA, echo=FALSE}
question("Select the cases where ANOVA is appropriate",
         answer("A professor has three classes and you want to compare the professor's assessment of the three classes in comparison with each other"),
         answer("Three professors have one class each and you want to compare the mean class grades", correct = TRUE),
         answer("You want to compare white blood cell counts as a response to medication for four groups of patients", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "You'll learn about independence between groups later, which matters for an ANOVA, but at this point, using common sense, you might be able to figure out why a design that uses only one professor to fill out assessments comparing three classes might introduce bias. Might comparing the classes against each cause a professor to inflate or deflate ratings to rank the classes rather than objectively assess them? And what about the categorical variable? How many categories does the variable `professor` have? If it has only one, then it is not a variable but a constant. Therefore there are not three groups to compare, but just one: and that just won't work."
)
```
<div id="filter-hint">
**Hint:** If you have just one professor and three classes, then the nominal variable (`professor`) is a constant. You need a nominal variable with two or more groups and a [measurement](http://www.biostathandbook.com/variabletypes.html#measurement) variable to perform an ANOVA.
</div>

In a one-way ANOVA (also known as a _one-factor_, _single-factor_, or _single-classification_ ANOVA), there is one measurement variable and one nominal variable. You make multiple observations of the measurement variable for each value of the nominal variable. 

For example, here is some data on a shell measurement (the length of the anterior adductor muscle scar, or AAM length, standardized by dividing by length) in the mussel *Mytilus trossulus* from five locations: Tillamook, Oregon; Newport, Oregon; Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland.

```{r data1, echo=FALSE}
mussels
```

The nominal variable is invisible but implicit in the data structure. It's `location`, with the five values `Tillamook`, `Newport`, `Petersburg`, `Magadan`, and `Tvarminne`. There are six to ten observations of the measurement variable, AAM length (`aam`), from each location. Again, `aam` is implicit: you won't find a column called "aam", but all the values in the columns we do have are values for `aam`. 

The data needs a bit of munging to be ready for analysis. 

```{r select-variables, echo=FALSE}
question("Which _explicit_ variables do we have in the `mussels` data as it is?",
         answer("Tillamook", correct = TRUE),
         answer("Newport", correct = TRUE),
         answer("Petersburg", correct = TRUE),
         answer("Magadan", correct = TRUE),
         answer("Tvarminne", correct = TRUE),
         answer("aam"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "You found them all!",
         incorrect = "The column names in the dataset `mussels` are the variables."
)
```

```{r how-to-modify-data, echo=FALSE}
question("Which variables do we actually want to analyze?",
         answer("location", correct = TRUE),
         answer("aam", correct = TRUE),
         answer("country"),
         answer("city"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "That's right. Just two variables will do the trick.",
         incorrect = "You need only two variables as described in the paragraph above these two questions."
)
```


## How to Prepare your Data for a One-Way ANOVA in R

You should, before any call to a statistical function, ensure that the data is in the correct format for running the analysis. For an ANOVA, remember, you should have one [nominal (a.k.a. "categorical") variable](http://www.biostathandbook.com/variabletypes.html#nominal) variable with 2 or more categories and one [measurement (a.k.a. "scalar")](http://www.biostathandbook.com/variabletypes.html#measurement) variable. 

Start by looking at the data again.

```{r look-at-mussels-again, exercise = TRUE, exercise.lines = 5}

```
```{r look-at-mussels-again-solution}
mussels
```

To use the language of `tidyverse`s `gather` and `spread` functions, we have a bunch of "key" variables that should actually be levels in a `location` variable. And we have a bunch of "values", anterior adductor muscle (AAM) scar lengths, that should actually be the `aam` variable. 

In short, we will convert the implicit variable `location` into a factor variable and the implicit variable `aam` into a scalar variable. 

The terms "key" and "value", as used in `gather` and `spread`, have proven difficult to communicate to many R users. The folks who created the `tidyverse` therefore set up some new functions, `pivot_longer` and `pivot_wider`, that they hoped would prove easier for people to understand. The `gather` and `spread` functions aren't being maintained any more. You might have learned them elsewhere, but you may want to learn the new functions now. 

So your first step may be to check out our lesson [Pivot Longer](../sb-pivot-longer/) if you haven't used `pivot_longer` before to transform a wide data set to a narrower, longer one. Your work will still be here when you get back. 

#### Convert Wide Data to Long Data by using `pivot_longer`

Using the method from [Pivot Longer](../sb-pivot-longer/), enter the code for making the the wide version of `mussels` longer here. Store the output from your call to `pivot_longer` in `long_mussels`. 

Remember to set the new `location` variable in `long_mussels` to be a factor once you've created `long_mussels`.

If you haven't time to do the [Pivot Longer](../sb-pivot-longer/) lesson, use the Hints buttons to teach yourself the proper syntax for the `pivot_longer` function.

Make sure you enclose your assignment commands in parentheses so you can see what they are doing without having to add another line to display results. 

```{r pivot-in-prep-for-anova, exercise = TRUE, exercise.lines = 10}

```
```{r pivot-in-prep-for-anova-hint-1}
long_mussels <- pivot_longer(data = ...,
                             cols = ...)
```
```{r pivot-in-prep-for-anova-hint-2}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(...)))
```
```{r pivot-in-prep-for-anova-hint-3}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = ...,
                             values_to = ...))
```
```{r pivot-in-prep-for-anova-hint-4}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam"))
```
```{r pivot-in-prep-for-anova-solution}
(long_mussels <- pivot_longer(data = mussels,
                             cols = names(mussels),
                             names_to = "location",
                             values_to = "aam"))
(long_mussels$location <- as.factor(long_mussels$location))
```

Now you have a beautiful data set with the two variables of interest. One variable is a factor (a categorical or nominal variable) and the other is a scalar or measurement variable. Now let's visualize this data set.

## Data Visualization for an ANOVA

As is typical with R, there are many ways to visualize the data. I'll show you two of the easiest here.

### Quickly Visualize the Data with a Boxplot

You can uickly visualize `long_mussels` with a `boxplot` using the R formula interface (`aam ~ location`) in a call to `boxplot`. Send `boxplot` that formula and tell it that the data is `long_mussels`. 

```{r boxplot, exercise = TRUE, exercise.lines = 5}

```
```{r boxplot-hint-1}
boxplot(...)
```
```{r boxplot-hint-2}
boxplot(aam ~ ..., ...)
```
```{r boxplot-hint-3}
boxplot(aam ~ location, data = ...)
```
```{r boxplot-solution}
boxplot(aam ~ location, data = long_mussels)
```

You now have a beautiful, clean visualization to provide along with the results of your ANOVA.

```{r predict-the-finding, echo=FALSE}
question("Looking at the boxplot you just made, what do you think the results of an ANOVA will be?",
         answer("Not all the means are the same among locations.", correct = TRUE),
         answer("All the means are the same among locations.", message = "It's pretty clear from the boxplot that some `location` means are different from at least one other `location` mean."),
         answer("Petersburg and Tvarminne have the same means", message = "Although an ANOVA tells us whether any pairs means differ from each other, it doesn't tell us which pairs. You need a post hoc test to get that additional information."),
         answer("There are two groups of `aam` values", message = "Although you can see clear groups in the boxplot, an ANOVA does not tell you anything about groups. It tells you only that some means differ. You can run a post hoc test to find out more about groupings."),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "Unfortunately, no.",
         correct = "Yes!"
)
```

To learn more about base plotting, see our lessons [Base Graphics](../swirl-base-graphics/) and [Base Plotting System](../swirl-base-plotting-system/). For a discussion of data visualization principles, see [Principles of Analytic Graphs](../swirl-principles-of-analytic-graphs/). To learn how to plot in `ggplot`, see [`ggplot2` Part 1](../swirl-ggplot2-part-1/), [`ggplot2` Part 2](../swirl-ggplot2-part-2/), [`ggplot2` Extras](../swirl-ggplot2-extras/), and [Exploratory Graphs](../swirl-exploratory-graphs/).

### Quickly Visualize the Data with a Density Plot

Sometimes the most accurate way to compare levels of a variable against each other for the purpose of illustrating your ANOVA is by creating a density plot (which, at one point, was called a "joyplot"). 

`qplot` is a very handy way to use `ggplot2` quickly to create a plot. Place `ggplot2` in the library, then construct your call to `qplot` by passing 6 items to it:

* `data` set equal to `long_mussels`    
* `x` set equal to the variable `aam`    
* `geom` set equal to the string "density"    
* `color` set equal to the variable `location`    
* `fill` also set equal to the variable `location`    
* `alpha` set equal to .25

```{r qplot-density, exercise = TRUE, exercise.lines = 10}

```
```{r qplot-density-hint-1}
library(ggplot2)
qplot(...)
```
```{r qplot-density-hint-2}
library(ggplot2)
qplot(data = long_mussels, 
      ...)
```
```{r qplot-density-hint-3}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", 
      ...)
```
```{r qplot-density-hint-4}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", 
      color = location,
      fill = location,
      ...)
```
```{r qplot-density-solution}
library(ggplot2)
qplot(data = long_mussels, 
      x = aam, 
      geom = "density", 
      color = location,
      fill = location,
      alpha = .25)
```

Many people choose to show their data as boxplots because it is a cleaner visualization. However, the density plot provides a lot of information about our data:

* Means vary from ~.07 to ~.10
* Tvarminne is bi-modal    
* Not all the levels are normally distributed    
* 11 rows were deleted due to missingness, which means that not all the levels of `location` contain the same number of observations. 

Some of the problems we see are common in small data sets. The fact that we lost 11 rows is also interesting: are we sure we have designed the experiment properly? 

What is alpha? See [`ggplot2` Part 1](../swirl-ggplot2-part-1/), [`ggplot2` Part 2](../swirl-ggplot2-part-2/), [`ggplot2` Extras](../swirl-ggplot2-extras/) to find out. But you can also guess.

```{r what-is-alpha, echo=FALSE}
question("What is `alpha` in the density plot above?",
         answer("A value that tells us what is the cutoff for 'alpha variables'"),
         answer("The family of the colors to use"),
         answer("Color opacity", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "Good job!",
         incorrect = "Nope. Try again."
)
```

If this plot makes you wonder whether our data violates assumptions of ANOVA, then you are thinking like a data scientist! We'll talk more about assumptions later in this lesson.

Meanwhile, we soldier on. 

## At Last, Perform the ANOVA 

The `lm` function in the native `stats` package fits a linear model by [least squares](https://rcompanion.org/handbook/G_05.html), and can be used for a variety of analyses: [regression](../sb-correlation-and-linear-regression/), analysis of variance (what we're doing now), and [analysis of covariance](https://rcompanion.org/rcompanion/e_04.html), for instance.  The analysis of variance is then conducted either with the `anova` function in the `car` package for [Type II or Type III sum of squares](https://rcompanion.org/rcompanion/d_04.html), or with the `aov` function in the native `stats` package for [Type I sum of squares](https://rcompanion.org/rcompanion/d_04.html). 

```{r where-can-we-use-lm, echo=FALSE}
question("Which analyses can you do using the `lm` function?",
         answer("linear regression", correct = TRUE),
         answer("analysis of variance", correct = TRUE),
         answer("analysis of covariance", correct = TRUE),
         answer("Kruskal-Wallis test"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         correct = "`lm` is amazing. And so are you!",
         incorrect = "Doing a Kruskal-Wallis test with `lm` would be a bit like vacuuming with a wet mop: It's just not done, for very good reasons."
)
```

```{r two-functions-to-do-anova, echo=FALSE}
question("Which two functions can you use to run an analysis of variance?",
         answer("`stats`", message = "`stats` is a package, not a function."),
         answer("`aov`", correct = TRUE),
         answer("`lm`", correct = TRUE),
         answer("`car`", message = "`car` is a package, not a function."),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "",
         correct = "You got it!"
)
```
```{r two-packages-to-do-anova, echo=FALSE}
question("Name two packages that can you use to run an analysis of variance (of course there are more---this is R).",
         answer("`stats`", correct = TRUE),
         answer("`anova`", message = "`anova` is a function, not a package."),
         answer("`lm`", message = "`lm` is a function, not a package."),
         answer("`car`", correct = TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "",
         correct = "All your hard work is paying off!"
)
```

The simplest way to perform the analysis of variance procedure is using `aov` from the native `stats` package, accepting all its defaults. To see what the defaults are, type `?aov` at the command line.

Try running `aov` here. First, make sure that you have `stats` in the library. 

Next, store the results of your call to `aov` (which calls `lm`, among other things) in the variable `fit`. Pass `aov` the formula of interest (the measurement variable "across" or `~` the categorical variable) and the name of the data set in the form `data = long_mussels`. 

Finally, use `summary(fit)` to see the results. 

```{r aov-for-fun, exercise = TRUE, exercise.lines = 5}

```
```{r aov-for-fun-hint-1}
library(stats)
fit <- ?
summary(fit)
```
```{r aov-for-fun-hint-2}
library(stats)
fit <- aov(...)
summary(fit)
```
```{r aov-for-fun-solution}
library(stats)
fit <- aov(aam ~ location, data = long_mussels)
summary(fit)
```

(Hint: If you don't see any results, make sure you have asked to see a `summary` of `fit`.)

What does all this mean? Most people quickly focus on the _p_ value, which here is .0036. Apparently we can reject the null hypothesis that the means within the groups are the same. 

We also have more information: the test statistic $\displaystyle F$ (4.78), the degrees of freedom (4, 34), and the sums of the squares and the mean square values for location and for the residuals. When you report ANOVA results, you typically report $\displaystyle F$, the degrees of freedom, and the $\displaystyle p$ statistic.

```{r what-to-report, echo=FALSE}
question("Which of these numbers do you include when you report the results of an ANOVA?",
         answer("_p_", correct = TRUE),
         answer("_F_", correct = TRUE),
         answer("df", correct = TRUE),
         answer("the mean squares"),
         random_answer_order = TRUE,
         allow_retry = TRUE
)
```

Take note of the fact that 11 observations were deleted due to missingness. The levels do not all have the same number of values in them. Is this a problem? Perhaps. We'll talk more about that later.

Just for fun, run `aov` and allow the results to print without first storing them in `fit` and using `summary` to format them.

```{r name, exercise = TRUE, exercise.lines = 5}

```
```{r name-hint-1}
library(stats)
aov(...)
```
```{r name-hint-2}
library(stats)
aov(aam ~ location, ...)
```
```{r name-solution}
library(stats)
aov(aam ~ location, data = long_mussels)
```

This provides less information! That's why people usually summarize the fit. 

```{r two-ways-to-summarize-fit, echo=FALSE}
question("Which lines of code result in a summary of the fit for an ANOVA?",
         answer("`summary(aov(aam ~ location, data = long_mussels))`", correct = TRUE),
         answer("`fit <- aov(aam ~ location, data = long_mussels); summary(fit)`", correct = TRUE),
         answer("`fit <- aov(aam ~ location, data = long_mussels)`"),
         answer("`aov(aam ~ location, data = long_mussels)`"),
         random_answer_order = TRUE,
         allow_retry = TRUE,
         incorrect = "Here's a hint: In R, you can put multiple commands on the same line using `;` to separate them.",
         correct = "You are amazing!"
)
```

## You found something interesting! Now what?
 
If the analysis of variance indicates an interesting effect of the independent variable (here, `location`), you can conduct multiple comparisons _among_ the levels of this factor using Tukey or Least Significant Difference (LSD) procedures. (The problem of inflating the Type I Error Rate when making multiple comparisons is discussed in the [Multiple Comparisons chapter](http://www.biostathandbook.com/multiplecomparisons.html) in John H. McDonald's ([Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html)))  

R functions which make multiple comparisons usually allow for adjusting _p_ values. In R you can use the Benjamini–Hochberg (BH) or `fdr` procedure. See `?p.adjust` for more information.

START HERE

## Assumptions

One-way ANOVA assumes that the observations within each group are normally
distributed. It is not particularly sensitive to deviations from this assumption; if you apply
one-way ANOVA to data that are non-normal, your chance of getting a P value less than
0.05, if the null hypothesis is true, is still pretty close to 0.05. It’s better if your data are
close to normal, so after you collect your data, you should calculate the residuals (the
difference between each observation and the mean of its group) and plot them on a
histogram. If the residuals look severely non-normal, try data transformations and see if
one makes the data look more normal.

If none of the transformations you try make the data look normal enough, you can use
the Kruskal-Wallis test. Be aware that it makes the assumption that the different groups
have the same shape of distribution, and that it doesn’t test the same null hypothesis as
one-way ANOVA. Personally, I don’t like the Kruskal-Wallis test; I recommend that if you
have non-normal data that can’t be fixed by transformation, you go ahead and use oneway
ANOVA, but be cautious about rejecting the null hypothesis if the P value is not very far
below 0.05 and your data are extremely non-normal.
One-way ANOVA also assumes that your data are homoscedastic, meaning the standard
deviations are equal in the groups. You should examine the standard deviations in the
different groups and see if there are big differences among them.
If you have a balanced design, meaning that the number of observations is the same in
each group, then one-way ANOVA is not very sensitive to heteroscedasticity (different
standard deviations in the different groups). I haven’t found a thorough study of the
effects of heteroscedasticity that considered all combinations of the number of groups,
sample size per group, and amount of heteroscedasticity. I’ve done simulations with two
groups, and they indicated that heteroscedasticity will give an excess proportion of false
positives for a balanced design only if one standard deviation is at least three times the
size of the other, and the sample size in each group is fewer than 10. I would guess that a
similar rule would apply to one-way ANOVAs with more than two groups and balanced
designs.

Heteroscedasticity is a much bigger problem when you have an unbalanced design
(unequal sample sizes in the groups). If the groups with smaller sample sizes also have
larger standard deviations, you will get too many false positives. The difference in
standard deviations does not have to be large; a smaller group could have a standard
deviation that’s 50% larger, and your rate of false positives could be above 10% instead of
at 5% where it belongs. If the groups with larger sample sizes have larger standard
deviations, the error is in the opposite direction; you get too few false positives, which
might seem like a good thing except it also means you lose power (get too many false
negatives, if there is a difference in means).

You should try really hard to have equal sample sizes in all of your groups. With a
balanced design, you can safely use a one-way ANOVA unless the sample sizes per group
are less than 10 and the standard deviations vary by threefold or more. If you have a
balanced design with small sample sizes and very large variation in the standard
deviations, you should use Welch’s ANOVA instead.

If you have an unbalanced design, you should carefully examine the standard
deviations. Unless the standard deviations are very similar, you should probably use
Welch’s ANOVA. It is less powerful than one-way ANOVA for homoscedastic data, but it can
be much more accurate for heteroscedastic data from an unbalanced design.

## Tukey-Kramer 

If you reject the null hypothesis that all the means are equal, you’ll probably want to
look at the data in more detail. One common way to do this is to compare different pairs
of means and see which are significantly different from each other. For the mussel shell
example, the overall P value is highly significant; you would probably want to follow up
by asking whether the mean in Tillamook is different from the mean in Newport, whether
Newport is different from Petersburg, etc.

It might be tempting to use a simple two-sample t–test on each pairwise comparison
that looks interesting to you. However, this can result in a lot of false positives. When
there are a groups, there are (a2–a)/2 possible pairwise comparisons, a number that quickly
goes up as the number of groups increases. With 5 groups, there are 10 pairwise comparisons; with 10 groups, there are 45, and with 20 groups, there are 190 pairs. When you do multiple comparisons, you increase the probability that at least one will have a P value less than 0.05 purely by chance, even if the null hypothesis of each comparison is
true.

There are a number of different tests for pairwise comparisons after a one-way ANOVA,
and each has advantages and disadvantages. The differences among their results are fairly
subtle, so I will describe only one, the Tukey-Kramer test. It is probably the most
commonly used post-hoc test after a one-way ANOVA, and it is fairly easy to understand.
In the Tukey–Kramer method, the minimum significant difference (MSD) is calculated
for each pair of means. It depends on the sample size in each group, the average variation
within the groups, and the total number of groups. For a balanced design, all of the MSDs
will be the same; for an unbalanced design, pairs of groups with smaller sample sizes will
have bigger MSDs. If the observed difference between a pair of means is greater than the
MSD, the pair of means is significantly different. 

Perform the analysis with the `TukeyHSD` function from the `stats` package.

```{r tukey, exercise = TRUE}
libray(stats)
fit <- aov(aam ~ location, data = long_mussels)
summary(fit)
TukeyHSD(fit)
```


## Welch’s ANOVA

If the data show a lot of heteroscedasticity (different groups have different standard
deviations), the one-way ANOVA can yield an inaccurate P value; the probability of a false
positive may be much higher than 5%. In that case, you should use Welch’s ANOVA.

Perform the analysis with the `oneway.test` function from the `stats` package. When the `var.equal` argument is set to `FALSE`, the Welch method is used. 

```{r welch, exercise=TRUE}
oneway.test(aam ~ location,data=long_mussels,var.equal=FALSE)
```

## Power Analysis

To do a power analysis for a one-way ANOVA is kind of tricky, because you need to
decide what kind of effect size you’re looking for. If you’re mainly interested in the overall
significance test, the sample size needed is a function of the standard deviation of the
group means. Your estimate of the standard deviation of means that you’re looking for
may be based on a pilot experiment or published literature on similar experiments.
If you’re mainly interested in the comparisons of means, there are other ways of
expressing the effect size. Your effect could be a difference between the smallest and
largest means, for example, that you would want to be significant by a Tukey-Kramer test.

As an example, let’s say you’re studying transcript amount of some gene in arm
muscle, heart muscle, brain, liver, and lung. Based on previous research, you decide that
you’d like the ANOVA to be significant if the means were 10 units in arm muscle, 10 units in
heart muscle, 15 units in brain, 15 units in liver, and 15 units in lung. The standard
deviation of transcript amount within a tissue type that you’ve seen in previous research
is 12 units. 

Perform the analysis with the `power.ANOVA.test` function from the `stats` package. You need to specify the number of groups with the `groups` argument, within group *variance* with the `within.var` argument, between group *variance* with the `between.var` argument, the signficiance value with `sig.level` and power with `power`. Recall that standard deviation is the square root of variance. 

```{r power, exercise=TRUE}
# group_means <- c(10, 10, 15, 15, 15)
# experiment_var <- 12^2
# power.ANOVA.test(groups = 5, 
#                  within.var = experiment_var, 
#                  between.var = var(group_means), 
#                  sig.level = 0.05, power = 0.80)
```

Since there are five groups, you’d need 59 observations per group to have an 80% chance of having a significant (P<0.05) one-way ANOVA.

Alternatively, if you have no experimental data, you can use the `cohen.ES` function to estimate effect sizes and the `pwr.ANOVA.test` function from the `pwr` package. 

```{r cohen, exercise=TRUE}
# library(pwr)
# effect_size <- cohen.ES(test="anov",size="small")$effect.size
# pwr.ANOVA.test(k = 5, 
#                f = effect_size,
#                sig.level = 0.05, power = 0.80)

```

## But I like math. Where's the math?

The basic idea is to calculate the mean of the observations within each group, then
compare the variance **among** these means to the average variance **within** each group.

Let's state that slightly differently: Under the null hypothesis that the observations in the different groups all have the same mean, the weighted **among-group** variance will be the same as the **within-group** variance. 

As the means get further apart, the variance **among** the means increases. 

The test statistic is _F_: the ratio of the variance **among** the group means _divided by_ the average variance **within** the groups. 

> $\displaystyle F = \frac{Var_a}{Var_w}$,

where $\displaystyle Var_a = $ variance _among_ group means and $\displaystyle Var_w =$ the average variance _within_ the values in each group.


The $\displaystyle F$ statistic has a known distribution under the null hypothesis, so you can calculate the
probability of obtaining the observed $\displaystyle F$ under the null hypothesis.
The shape of the $\displaystyle F$-distribution depends on two degrees of freedom:

* the degrees of
freedom of the numerator (among-group variance)    
* degrees of freedom of the
denominator (within-group variance). 

The _among-group degrees of freedom_ is the
number of groups minus one. 

The _within-groups degrees of freedom_ is the total number
of observations minus the number of groups. 

If there are $\displaystyle n$ observations in $\displaystyle A$ groups,

* numerator degrees of freedom is $\displaystyle n - 1$     
* denominator degrees of freedom is $\displaystyle n - A$. 

For the
example data set, there are 5 groups and 39 observations, so 

* the numerator degrees of
freedom is $\displaystyle 5 - 1 = 4$      
* the denominator degrees of freedom is $\displaystyle 39 - 5 = 34$. 

In order to check where your results fall under the $\displaystyle F$ distribution, you need three pieces of information (if you are calculating by hand): the value of $\displaystyle \frac{Var_a}{Var_w}$, the numerator degrees of freedom (here 4) and the denominator degrees of freedom (here 34). 

But you can always take the easy way out and use R to calculate your $\displaystyle F$ statistic and its accompanying _p_ value for you. 

## References 

This lesson is heavily based with thanks on the works of John H. McDonald ([Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html)) and Salvatore S. Mangiafico ([R Companion to the Biostats Handbook](https://rcompanion.org/rcompanion/b_03.html)).

## See Also 

[Kruskall Wallis test](../Kruskal-Wallis/).