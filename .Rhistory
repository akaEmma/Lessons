'Brendon Small'     6      40     1975    1177      76
'Brendon Small'     6      44     2116    1262      84
'Brendon Small'     6      45     2161    1271      86
'Brendon Small'     6      44     2091    1222      87
'Brendon Small'     6      48     2236    1377      90
'Brendon Small'     6      47     2198    1288      78
'Brendon Small'     6      46     2190    1284      89
'Jason Penopolis'   7      45     2134    1262      76
'Jason Penopolis'   7      45     2128    1281      80
'Jason Penopolis'   7      46     2190    1305      84
'Jason Penopolis'   7      43     2070    1199      68
'Jason Penopolis'   7      48     2266    1368      85
'Jason Penopolis'   7      47     2216    1340      76
'Jason Penopolis'   7      47     2203    1273      69
'Jason Penopolis'   7      43     2040    1277      86
'Jason Penopolis'   7      48     2248    1329      81
'Melissa Robins'    8      48     2265    1361      67
'Melissa Robins'    8      46     2184    1268      68
'Melissa Robins'    8      53     2441    1380      66
'Melissa Robins'    8      48     2234    1386      65
'Melissa Robins'    8      52     2403    1408      70
'Melissa Robins'    8      53     2438    1380      83
'Melissa Robins'    8      52     2360    1378      74
'Melissa Robins'    8      51     2344    1413      65
'Melissa Robins'    8      51     2351    1400      68
'Paula Small'       9      52     2390    1412      78
'Paula Small'       9      54     2470    1422      62
'Paula Small'       9      49     2280    1382      61
'Paula Small'       9      50     2308    1410      72
'Paula Small'       9      55     2505    1410      80
'Paula Small'       9      52     2409    1382      60
'Paula Small'       9      53     2431    1422      70
'Paula Small'       9      56     2523    1388      79
'Paula Small'       9      50     2315    1404      71
'Coach McGuirk'    10      52     2406    1420      68
'Coach McGuirk'    10      58     2699    1405      65
'Coach McGuirk'    10      57     2571    1400      64
'Coach McGuirk'    10      52     2394    1420      69
'Coach McGuirk'    10      55     2518    1379      70
'Coach McGuirk'    10      52     2379    1393      61
'Coach McGuirk'    10      59     2636    1417      70
'Coach McGuirk'    10      54     2465    1414      59
'Coach McGuirk'    10      54     2479    1383      61
")
diet = read.table(textConnection(Input),header=TRUE)
rm(Input)
ex_fit <- summary(lm(Pulse ~ Speed,
data = exercise))
egg_fit <- lm(Eggs ~ Weight,
data = egg)
egg_sum <- summary(egg_fit)
diverse_fit <- lm(Species ~ Latitude,
data = diversity)
my_cor_pwr <- pwr.r.test(n = NULL,
r = 0.500,
sig.level = 0.05,
power = 0.80,
alternative = "two.sided")
egg$ln_Weight <- log(egg$Weight)
ln_egg_fit <- lm(Eggs ~ ln_Weight, data = egg)
sef <- summary(egg_fit)
slef <- summary(ln_egg_fit)
# Chunk 2: nolinregorcor
question("Select any questions that can be answered using correlation or linear regression",
answer("Is there a relationship between my dog's food intake and the amount of exercise she gets?", correct = TRUE),
answer("What is the strength of the relationship between calories and amount of sodium in an athlete's diet?", correct = TRUE),
answer("Can I predict how many eggs an amphipod carries by weighing her?", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 3: bb
question("What are NOT examples of a correlation or linear regression null hypothesis?",
answer("My electric bill is always high.", correct = TRUE),
answer("My electric bill is high no matter how much television I watch."),
answer("My electric bill is low no matter how much television I watch"),
answer("I watch a lot of television.", correct = TRUE),
allow_retry = TRUE,
random_answer_order = TRUE
)
# Chunk 4: corregpackages
if(!require(psych)){install.packages("psych")}
if(!require(PerformanceAnalytics)){install.packages("PerformanceAnalytics")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(rcompanion)){install.packages("rcompanion")}
if(!require(gvlma)){install.packages("gvlma")}
if(!require(pwr)){install.packages("pwr")}
# Chunk 5: exercise
# Chunk 6: exercise-solution
exercise
# Chunk 7: passpulse
# Chunk 8: passpulse-solution
plot(exercise)
# Chunk 9: egg
# Chunk 10: egg-solution
egg
plot(egg)
# Chunk 11: plotdiversity
# Chunk 12: plotdiversity-solution
plot(Species ~ Latitude,
data = diversity,
pch = 16)
# Chunk 13: helpcortest
# Chunk 14: helpcortest-solution
?cor.test
# Chunk 15: cordiversity
# Chunk 16: cordiversity-solution
(cordiv <- cor.test(~ Species + Latitude,
data = diversity,
method = "pearson",
conf.level = 0.95))
# Chunk 17: tf_proof
question("True or false: You have just proven that there is no relationship between the two variables.",
answer("True because _p_ > .05"),
answer("False because failing to reject the null is not the same as accepting it", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 18: pulsecor
# Chunk 19: pulsecor-solution
(corex <- cor.test(~ Pulse + Speed,
data = exercise,
method = "pearson",
conf.level = 0.95))
# Chunk 20: lmexer
# Chunk 21: lmexer-solution
lm(formula = Pulse ~ Speed,
data = exercise)
# Chunk 22: diverse_lm
# Chunk 23: diverse_lm-solution
(diverse_fit <- lm(Species ~ Latitude,
data = diversity))
summary(diverse_fit)
# Chunk 24: plainInterp
question("In plain English, what should you decide about the hypothesis?",
answer("Since _p_ is above .05, I will not reject the null hypothesis.", correct = TRUE),
answer("This is just too hard. I'm going to bag it."),
answer("Since _p_ is above .05, I will reject the null hypothesis."),
answer("The data isn't fit for hypothesis tests."),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 25: eggfit
# Chunk 26: eggfit-solution
egg_fit <- lm(Eggs ~ Weight,
data = egg)
summary(egg_fit)
# Chunk 27: q-cor-form
question("What is the intercept for the correlation between Weight and Eggs?",
answer("1.60"),
answer("63.5"),
answer("12.7", correct = TRUE),
answer("0"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 28: interpret
question("Interpret the meaning of _b_ in the regression formula for Eggs and Weight.",
answer("For every 1 unit increase in weight, we expect 3.75 more eggs."),
answer("For every 3.75 change in latitude we expect the number of species to be 1 more."),
answer("For every 1 unit increase in weight, we expect an increase of 1.60 eggs.", correct = TRUE),
answer("For every additional mg in weight, we expect 1.60 more eggs."),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 29: pegg
question("What is the value of _p_ for the linear regression of Eggs and Weight?",
answer("3.74"),
answer(".206"),
answer(".175"),
answer(".0154", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 30: tfdiffs
question("True or false: There are real differences between correlation and linear regression",
answer("True", correct = TRUE),
answer("False"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 31: tfdiffsmatter
question("True or false: The differences between correlation and linear regression matter a great deal in every data set",
answer("True"),
answer("False", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 32: maindiff
question("Which of the following are NOT differences between correlation and regression?",
answer("In regression, you choose an independent variable's values"),
answer("In correlation, you choose both variables' values", correct = TRUE),
answer("In regression, you sample both measurement variables randomly from a population", correct = TRUE),
answer("In correlation, you sample both measurement variables from a population"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 33: whycorr
question("Why is the foot and height example a correlation and not a regression?",
answer("Because it is a meaningful estimate of the strength of the association between two variables"),
answer("Because you took measurements of both variables from a random sample", correct = TRUE),
answer("Because you can't compare the strength of this association with the strengths of associations between other variables"),
answer("Because _p_ is significant"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 34: whyreg
question("Why is this analysis correctly run as a regression rather than as a correlation?",
answer("Because you find forensic anthropology to be disgusting"),
answer("Because you decided which temperatures to use", correct = TRUE),
answer("Because temperature is a dependent variable"),
answer("Because you don't have to calculate the strength of the relationship"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 35
knitr::include_graphics("https://storage.googleapis.com/public-braunsb-media/Arcus-Education-Assets/Lessons/images/three-graphs-of-simulated-data.png")
# Chunk 36: tflizards
question("True or false: A wider range of values tends to cause the relationship between two variables to become stronger.",
answer("True", correct = TRUE),
answer("False"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 37: whichregcor
question("Which of the following MUST be a regression?",
answer("You go out to the desert every Saturday for eight months and measure air temperature and lizard running speed"),
answer("You want to see whether there is a relationship between two variables"),
answer("You want to compare the strength of the relationship between two variables with the strength of other relationships"),
answer("You first determing your X values, then do the experiment to see what the Y values turn out to be", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 38: possible-reasons
question("Which of the following might be true if you find a correlation between two variables?",
answer("The first causes the second", correct = TRUE),
answer("The second causes the first", correct = TRUE),
answer("They are unrelated but are both caused to change by a third variable", correct = TRUE),
answer("They are unrelated and you are seeing a random occurence of correlation", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 39: corcauseshoes
question("Can we now conclude that longer thumbs make you tie your shoes faster?",
answer("Yes, because we got rid of the confounding age variable."),
answer("No, because reasons.", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 40: sneer
question("Should we dismiss correlations without further evidence?",
answer("No, because they are an indication that something, known or unknown, may be going on that should be investigated further", correct = TRUE),
answer("Yes, because some correlations are not causations"),
answer("Yes, because correlation is not causation"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 41: selectallhelpfulthings
question("Which strategies help to prevent misunderstanding the fruit & veg leading to lower blood pressure hypothesis?",
answer("Control for socioeconomic variables", correct = TRUE),
answer("Use multiple regression to control statistically for confounders", correct = TRUE),
answer("Perform animal studies to see if the original hypothesis holds true with them in a highly controlled environment", correct = TRUE),
answer("Perfrom a clinical trial", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 42: what-elements-for-regression
question("Which of the following elements are part of a good regression design?",
answer("control for sex, age, and socioeconomic status", correct = TRUE),
answer("randomly choose treatment level for each participant", correct = TRUE),
answer("have participants follow a protocol for a given time", correct = TRUE),
answer("measure the dependent variable after the treatment protocol is complete", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 43: good_pearsons
question("Which of the following need to be true for accurate results from a Pearson correlation? (Please select ALL that apply)",
answer("Both variables must be either scalar or ratio, because ratios are like scalar variables", correct = TRUE),
answer("The two variables, taken together, must be bivariate normal", correct = TRUE),
answer("No outliers", correct = TRUE),
allow_retry = TRUE,
random_answer_order = TRUE
)
# Chunk 44: good_kendall
question("Which of the following need to be true for accurate results from a Kendall correlation? (Please select ALL that apply)",
answer("The variables must be either scalar or ordinal", correct = TRUE),
answer("The two variables, taken together, must be bivariate normal"),
answer("No outliers"),
allow_retry = TRUE,
random_answer_order = TRUE
)
# Chunk 45: good_spearman
question("Which of the following need to be true for accurate results from a Spearman correlation? (Please select ALL that apply)",
answer("The variables must be either scalar or ordinal", correct = TRUE),
answer("The two variables, taken together, must be bivariate normal"),
answer("No outliers"),
allow_retry = TRUE,
random_answer_order = TRUE
)
# Chunk 46: good_lm
question("Which of the following need to be true for accurate results in a linear model? (Please select ALL that apply)",
answer("The variables must be either scalar or ordinal", correct = TRUE),
answer("The relationship between the variables must be linear", correct = TRUE),
answer("The bivariate distribution of the variables must be normal", correct = FALSE),
answer("The variables must be independent", correct = FALSE),
answer("The variables must be homoscedastic", correct = FALSE),
answer("The distributions of the residuals must be normal", correct = TRUE),
answer("The residuals must be independent", correct = TRUE),
answer("The residuals must be homoscedastic", correct = TRUE),
answer("Outliers must be treated with robust linear regression methods", correct = TRUE),
allow_retry = TRUE,
random_answer_order = TRUE
)
# Chunk 47: xaxis
question("Which goes on the X axis?",
answer("the dependent variable"),
answer("an independent variable", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 48: yaxis
question("Which goes on the Y axis?",
answer("the dependent variable", correct = TRUE),
answer("an independent variable"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 49: paying-attention
question("That was a long chunk of text with no review questions. Are you still paying attention?",
answer("Yes", correct = TRUE),
answer("No", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 50: to_skip_or_not_to_skip
question("What do you want to do?",
answer("Skip to 'Perform the Analysis'"),
answer("Find out how to do ethical research and set myself up for success", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 51: gvlma_egg
# Chunk 52: gvlma_egg-solution
summary(gvlma(egg_fit))
plot(gvlma(egg_fit))
# Chunk 53: div_fit_gvlma
# Chunk 54: div_fit_gvlma-solution
summary(gvlma(diverse_fit))
plot(gvlma(diverse_fit))
# Chunk 55: which_model_meets_assumptions
question("Which of the two models passes all necessary assumptions for linear regression?",
answer("`egg_fit`"),
answer("`diverse_fit`", correct = TRUE),
answer("A model airplane"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 56: pwr-correlation
# Chunk 57: pwr-correlation-solution
library(pwr)
pwr.r.test(n = NULL,
r = 0.500,
sig.level = 0.05,
power = 0.80,
alternative = "two.sided")
# Chunk 58: how_many_egg
# Chunk 59: how_many_egg-solution
nrow(egg)
# Chunk 60: gettoknwmtcars
# Chunk 61: gettoknwmtcars-solution
names(mtcars)
head(mtcars)
str(mtcars)
# Chunk 62: rcorr
# Chunk 63: rcorr-solution
library(Hmisc)
rcorr(as.matrix(mtcars))
# Chunk 64: corrgram
# Chunk 65: corrgram-solution
library(corrgram)
corrgram(mtcars)
# Chunk 66: whatcolor
question("What color is the cell that shows the correlation between `wt` and `gear` in the `corrgram` output you just made?",
answer("pale blue"),
answer("pink"),
answer("medium red"),
answer("red", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 67: whatcolor2
question("What color is the correlation between `cyl` and `hp`?",
answer("pale blue"),
answer("dark blue", correct = TRUE),
answer("pink"),
answer("red"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 68: corrgram2
# Chunk 69: corrgram2-solution
corrgram(mtcars,
order = TRUE)
# Chunk 70: uppernull
# Chunk 71: uppernull-solution
corrgram(mtcars,
order = TRUE,
upper.panel = NULL)
# Chunk 72: mtcarsupperpie
# Chunk 73: mtcarsupperpie-solution
corrgram(mtcars,
order = TRUE,
upper.panel = panel.pie)
# Chunk 74: interpcorrcol
question("What does a dark red pie indicate in a correlogram?",
answer("A strong positive correlation"),
answer("A strong negative correlation", correct = TRUE),
answer("A weak negative correlation"),
answer("A weak positive correlation"),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 75: panel.text
# Chunk 76: panel.text-solution
corrgram(mtcars,
order = TRUE,
upper.panel = panel.pie,
main = "Car Mileage Correlations in PCA Order")
# Chunk 77: interesting
# Chunk 78: interesting-solution
corrgram(mtcars,
order = TRUE,
lower.panel = panel.ellipse,
upper.panel = panel.pts,
diag.panel = panel.minmax,
main = "Car Mileage Correlations in PCA Order")
# Chunk 79: pairsdivers
# Chunk 80: pairsdivers-solution
pairs(diet)
pairs(mtcars)
# Chunk 81: scanpairs
question("Which relationships from the `mtcars` data set might be strongly correlated?",
answer("`disp` and `hp`", correct = TRUE),
answer("`drat` and `vs`"),
answer("`qsec` and `hp`", correct = TRUE),
answer("`carb` and `mpg`", correct = TRUE),
random_answer_order = TRUE,
allow_retry = TRUE
)
# Chunk 82: splom
# Chunk 83: splom-solution
super.sym <- trellis.par.get("superpose.symbol")
splom(~iris[1:4], groups = Species, data = iris,
panel = panel.superpose,
key = list(title = "Three Varieties of Iris",
columns = 3,
points = list(pch = super.sym$pch[1:3],
col = super.sym$col[1:3]),
text = list(c("Setosa", "Versicolor", "Virginica"))))
# Chunk 84: egg_fit_again
# Chunk 85: egg_fit_again-solution
egg_fit <- lm(Eggs ~ Weight, data = egg)
summary(egg_fit)
# Chunk 86: anova-best-fit
# Chunk 87: anova-best-fit-solution
anova(egg_fit)
# Chunk 88: sumegg_fit
# Chunk 89: sumegg_fit-solution
summary(egg_fit)
anova(egg_fit)
load("~/Documents/GitHub/a-MESS Lessons/plants.Rdata")
View(load("~/Documents/GitHub/a-MESS Lessons/plants.Rdata"))
View("~/Documents/GitHub/a-MESS Lessons/plants.Rdata")
plants <- load("plants.RData")
plants
getwd()
lazyload("plants.RData")
ls
rm(plants)
load("plants.RData")
plants
write.csv(plants, "swirl-looking-at-data/plants.csv")
library(readr)
read_csv("swirl-looking-at-data/plants.csv")
read_csv("plants.csv")
plants <- read_csv("plants.csv")
plants <- plants %>%
select(-X1)
library(dplyr)
plants <- plants %>%
select(-X1)
names(plants)
ncol(plants)
plants <- read_csv("plants.csv")
plants <- read_csv("swirl-looking-at-data/plants.csv")
names(plants)
ncol(plants)
plants <- plants %>%
select(-X1)
flips <- sample(c(0, 1), 100, replace = TRUE, prob = c(0.3, 0.7))
set.seed(9699)
flips <- sample(c(0, 1), 100, replace = TRUE, prob = c(0.3, 0.7))
set.seed(9699)
flips2 <- rbinom(100, size = 1, prob = 0.7)
install.packages("twitteR")
install.packages("twitterwidget")
?twitterwidget
library(twitteR)
library(twitterwidget)
?twitterwidget
options(scipen = 99999, digits = 3)
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 99999, digits = 3)
