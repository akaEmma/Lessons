---
title: "ANOVA"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
options(digits = 3, scipen = 9999)
if(!require(learnr)){install.packages("learnr")}
library(learnr)
this_Input =("

")

```

This lesson is both a reference and a tutorial. It contains all the code samples you need to perform an ANOVA on your own data as well as background information such as how to interpret output and which graphs you might want to use to demonstrate results (and in some cases which graphs _not_ to use). 

You can also learn to udnerstand and perform an ANOVA by working through the lesson from start to finish. 

## What kinds of Variables work with a _t_ Test

>* One [scalar (a.k.a. "measurement") variable](http://www.biostathandbook.com/variabletypes.html#measurement)     
* One [nominal variable](http://www.biostathandbook.com/variabletypes.html) with only two categories or two categories that you have selected. You can also use a binary variable here as it is functionally a nominal variable with two categories. 
Student's _t_ test for two samples shows whether the means of the measurement variable are significantly different in two groups. 

## Null and Alternative Hypotheses

>* **H<sub>0</sub>**: The means of the measurement variable are equal in the two groups.     
* **H<sub>A</sub>** (2-sided): The means of the measurement variable are not equal in the two groups.     
* **H<sub>A</sub>** (1-sided): The mean of the measurement variable is higher (specifically---or lower specifically, but not either-or because that would be a 2-sided test) in one of the groups.

```{r bb, echo=FALSE}
question("What is NOT an example of a 1-sided null hypothesis?",
         answer("It usually takes less than one hour to make pie dough"),
         answer("The average monthly electric bill in Philadelphia, PA is ", correct = TRUE),
         answer("The average monthly electric bill in Philadelphia, PA is less than "),
         answer("The average monthly electric bill in Philadelphia, PA is more than "),
         allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## Examples of the Null and Alternative Hypotheses

You have become curious about hand sizes. Are right hands the same size as left hands?

There are two variables in that question. 

```{r two-vars, echo=FALSE}
question("What are the two variables?",
         answer("right hands and left hands"),
         answer("hand size and type of person (politician vs. lumberjack)"),
         answer("hand size and hand type (left vs. right)", correct = TRUE),
         allow_retry = TRUE,
  random_answer_order = TRUE
)
```

In fall 2004, students in the 2 p.m. section of John McDonald's Biological Data Analysis class had an average height of 66.6 inches, while the average height in the 5 p.m. section was 64.6 inches. Are the average heights of the two sections significantly different? 

First, let's look at the data. It's been loaded in `ht` for you. Use `head` to look at it, then change the variable names. There are lots of ways to change variable names in R. In this case, try simply stating `names(ht) <- c("section", "inches")`. Then type `names(ht)` to see if it worked. 

```{r heightnames, exercise = TRUE}

```
```{r heightnames-solution}
head(ht)
names(ht) <- c("section", "inches")
names(ht)
```

The null hypothesis and alternatives are, therefore

>* **Example H<sub>0</sub>**: "Mean heights in the two sections are the same."     
* **Example H<sub>A</sub>** (2-sided): "Mean heights in the two sections are not the same."     
* **Example H<sub>A</sub>** (1-sided, version 1): "Mean height in the 2 pm section is higher than in the 5 pm section."     
* **Example H<sub>A</sub>** (1-sides, version 2): "Mean height in the 5 pm section is higher than in the 2 pm section."     

## Background

There are several statistical tests that use the _t_ distribution ([What's a distribution?](https://www.khanacademy.org/math/statistics-probability/displaying-describing-data/comparing-features-distributions/v/comparing-distributions?modal=1)) and can be called _t_ tests. One is Student's _t_ test for two samples, named after "Student," the pseudonym William Gosset used to hide his employment by the Guinness brewery in the early 1900s (they had a rule that their employees weren't allowed to publish, and Guinness didn't want other employees to know that they were making an exception for Gosset). Student's _t_ test for two samples compares the means in two groups.

```{r aa, echo=FALSE}
question("What might have been one of Student's favorite pasttimes?",
      answer("Drinking beer", correct = TRUE),
      answer("Working as a hairdresser"),
      answer("Flying to Jupiter's moons"),
      answer("Going to school full time"),
         allow_retry = TRUE
)
```

## Assumptions

Every statistical test relies upon assumptions about the data you give it. The next few sections are about the assumptions upon which an ANOVA rests. Note that the _t_ test is fairly reliable even when assumptions are violated, within reason. 

### Normality

The ANOVA assumes that the observations _within each group_ (as opposed to all of the observations together before you broke them into groups) are normally distributed. 

```{r bad_distributions, echo=FALSE}
question("Which of the following situations needs to be true for the same data set to result in too many false positives from an ANOVA? (Please select ALL that apply)",
         answer("A very small sample size", correct = TRUE),
         answer("A flat distribution", correct = TRUE),
         answer("A bimodal distribution", correct = TRUE),
         allow_retry = TRUE,
  random_answer_order = TRUE
)
```

```{r tt_tf_assumptions, echo=FALSE}
question("True or false: You can usually still perform a reliable test if only two out of three of the conditions in the previous question have been met.",
         answer("TRUE", correct = TRUE),
         answer("FALSE"),
         allow_retry = TRUE,
  random_answer_order = TRUE
)
```

### Homoscedasticity

In addition to normality, the ANOVA also assumes homoscedasticity (equal variances in the two groups). If you have a balanced design (equal sample sizes in the two groups), the test is not very sensitive to heteroscedasticity unless the sample size is very small (less than 10 or so); the standard deviations in one group can be several times as big as in the other group, and you'll get _p_ < 0.05 about 5% of the time if the null hypothesis is true. 

With an unbalanced design, heteroscedasticity is a bigger problem; if the group with the smaller sample size has a bigger standard deviation, the ANOVA can give you false positives much too often. If your two groups have standard deviations that are substantially different (such as one standard deviation is twice as big as the other) and your sample sizes are small (less than 10) or unequal, you should use Welch's _t_ test instead.

```{r unbalanced, echo=FALSE}
question("What can cause an ANOVA to become more sensitive to the assumption of homoscedasticity?",
         answer("Heteroscedasticity"),
         answer("A very small sample (< 10 or so) and unequal sample sizes in the two groups", correct = TRUE),
         answer("Skewness in the data"),
         answer("Unequal sample sizes in the two groups"),
  random_answer_order = TRUE,
  allow_retry = TRUE
)
```

## Practice an ANOVA

I would love to have been able to plunk a code chunk here for you so you could perform this test without being confused with too many facts. In fact, you can scroll down to "Perform the Analysis" if you want to keep things that simple. And most of the time--especially with a _t_ test--you'll be fine if you do that. 

However, you have a reputation to protect (as do I), which means you need to make sure that all of this is true:

* you haven't made any faulty assumptions about the data that would render your analysis meaningless    
* you have established what a meaningful effect size is in the real world    
* that you have sufficient power to find an effect if one exists    
* that once you have run the test, you can understand the output

That's why the "Practice" section of this lesson isn't just a few lines of code.

```{r to_skip_or_not_to_skip, echo=FALSE}
question("What do you want to do?",
         answer("Skip to 'Perform the Analysis'"),
         answer("Find out how to do ethical research and set myself up for success", correct = TRUE),
  random_answer_order = TRUE,
  allow_retry = TRUE
)
```

### First Test the Assumptions
 
We will use a histogram with an imposed normal curve to confirm data are approximately normal. First, though, let's just look at the data. We'll use functions from the `psych` package, so be sure to call `library(psych)` before calling the functions `headTail`, `str`, and `summary`, passing `ht` to each of them. 

```{r f, exercise = TRUE}

```
```{r f-solution}
library(psych)
headTail(ht)
str(ht)
summary(ht)
```

Use the function `plotNormalHistogram` from the `rcompanion` package to see if the data is approximately normally distributed. All the function requires is the variable with the heights in inches, `ht`. Make sure to put `rcompanion` into the library before calling `plotNormalHistogram`.

```{r g, exercise = TRUE}

```
```{r g-solution}
library(rcompanion)
plotNormalHistogram(ht)
```

The shape is not normal. Let's look at a normal quantile plot of the data to find out more. Pass `ht` to `qqnorm`. Evaluate the resulting plot. It needs a red line, so call `qqline` and pass it `ht` and tell it to use `col` equal to "red".

```{r h, exercise = TRUE}

```
```{r h-solution}
qqnorm(ht)
qqline(ht, col = "red")
```

A perfectly normal distribution would have the dots exactly along the line. This is not perfectly normal, but it shows that the wonky histogram may have been due to the small sample size. There is a seemingly big difference between 2 people who are 65" tall and 6 people who are 66" tall, but in fact it's not all that damaging to our estimate of _t_. 

The example passes assumption tests for an ANOVA.

## Effect Size: How much of a Difference do we Care About?

The effect size estimation is calculated on the basis of the groups means and standard deviations in the case of an ANOVA. 

#### Identify a Meaningful Effect Size: Calculate Cohen's _d_

Calculate Cohen's _d_ for the example data. Put the package `lsr` in the library first as you do for the one-sample _t_ test. However, when you have two means in the same data set, the syntax is different. Pass `cohensD` the formula `inches ~ section`, then set the `data` parameter equal to `ht`, then, because the two groups in our dataset have different counts, set the `method` parameter equal to "unequal". Assign the output to a new variable, `ht_d`, then put parentheses around the entire statement so you can see the output even though it is being assigned to a variable. 

```{r r, exercise = TRUE}

```
```{r r-solution}
library(lsr)
(ht_d <- cohensD(inches ~ section, data = ht, method  = "unequal"))
```

### Interpret Cohen's _d_

Cohen's _d_ ranges from 0 to $\normalsize \infty$, with 0 indicating no effect: the means are equal. Cohen’s _d_ can be positive or negative depending on whether one mean is greater than or less than the other. It is closely related to the standard deviation. 

### Relating Cohen's _d_ to Effect Size in the World at Large

We use Cohen's _d_ to _standardize_ the effect size so we can compare the importance of the difference in height between the two sections with the importance of the difference between, say, distances between pairs of stars. We use Cohen's _d_ so scale does not confuse us. What's big or small in one situation is perhaps not so much in another situation.
 
A Cohen’s _d_ of 0.5 suggests that the means differ by one-half the standard deviation of the data. A Cohen’s _d_ of 1.0 suggests that the means differ by one standard deviation of the data.

Rule of thumb about effect sizes: 

* Small effect = 0.2    
* Medium effect = 0.5    
* Large effect = 0.8    

Look at `ht_d`. 

```{r ht_d_lookat, exercise = TRUE}

```
```{r ht_d_lookat-solution}
ht_d
```


```{r label, echo=FALSE}
question("What would you say the effect size is between heights based on the rule of thumb above?",
         answer("Small"),
         answer("Medium", correct = TRUE),
         answer("Large"),
  random_answer_order = TRUE,
  allow_retry = TRUE
)
```

## Power Analysis

To estimate the sample sizes needed to detect a significant difference between two means, you need the following:

* **The effect size**, or the difference in means you hope to detect.
* **The standard deviations of each of the two groups**. Usually you'll use the same standard deviation value for each group, but if you know ahead of time that one group will have a larger standard deviation than the other, you can use different numbers.
* **Alpha** ($\alpha$), or the significance level (usually 0.05)
* **Beta** ($\beta$), the probability of a false positive: accepting the null hypothesis when it is false. Common values for $\beta$ are 0.50, 0.80 and 0.90.
* **The ratio of one sample size to the other**. The most powerful design is to have equal numbers in each group such that $\frac{N1}{N2} = 1$, but sometimes it's easier to get large numbers of one of the groups. For example, if you're comparing the bone strength in mice that have been reared in zero gravity aboard the International Space Station vs. control mice reared on earth, you might decide ahead of time to use three control mice for every one expensive space mouse such that $\frac{N1}{N2} = 3$.

### Prep for the Power Analysis



### Calculate Power 



## Perform the Test



## Interprete the Output



### More about the Output

Run `t.test` again on the same data, but this time store the result in `tt_height`. 

```{r store_test_result, exercise = TRUE}

```
```{r store_result-solution}

```

In R, everything is an object. Use `str` (short for "structure"--and so many other things, but here all we care about is "structure") to find out what the output looks like to R. Pass `str` the object you just created.

```{r object_appearance, exercise = TRUE, exercise.setup = "prepare-height_ttest"}

```
```{r object_appearance-solution}
str(tt_height)
```

That's interesting. What looked like a paragraph of output was actually a list! Try accessing elements of the list, for instance, `method`.

```{r access_method, exercise = TRUE, exercise.setup = "prepare-height_ttest"}

```
```{r access_method-solution}
tt_height
```

You can use output very nicely in your [reproducible Markdown text](https://education.arcus.chop.edu/scripted-analysis/) by calling it within text while you write a Markdown document. For instance, you might write, "I just did a " and then type a tic-mark ("`", likely your lowercase "~", in the upper left corner of your keyboard, not to be confused with a single quote), then the text "r tt_height" without quotation marks, and finally, a closing tic-mark. The rendered (knitted) output would be 

>I just did a . 

Let's go through the _t_ test outputted ("put out"?) list one by one.

### Statistic



### Parameter



### `p.value`



### Confidence Interval



## Graph Results

```{r t, exercise = TRUE}

```
```{r t-solution}

```

## I _like_ Math. Where's the Math?



## References

This lesson is heavily based with thanks on the works of John H. McDonald ([Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html)) and Salvatore S. Mangiafico ([R Companion to the Biostats Handbook](https://rcompanion.org/rcompanion/b_03.html)).
